# Gemma 3 4B â€” gated model, requires HF token
# Prerequisites:
#   kubectl create secret generic hf-token -n inference --from-literal=token=hf_YOUR_TOKEN
apiVersion: kro.run/v1alpha1
kind: InferenceEndpoint
metadata:
  name: gemma-4b
  namespace: inference
spec:
  model: "google/gemma-3-4b-it"
  gpuCount: 1
  minReplicas: 1
  maxReplicas: 2
  workerMemory: "24Gi"
  workerCpu: "4"
  maxModelLen: 8192
