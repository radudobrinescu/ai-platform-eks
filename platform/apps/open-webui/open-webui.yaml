apiVersion: apps/v1
kind: Deployment
metadata:
  name: open-webui
  namespace: ai-platform
  labels:
    app: open-webui
spec:
  replicas: 1
  selector:
    matchLabels:
      app: open-webui
  template:
    metadata:
      labels:
        app: open-webui
    spec:
      containers:
        - name: open-webui
          image: ghcr.io/open-webui/open-webui:v0.8.5
          ports:
            - containerPort: 8080
          env:
            - name: OPENAI_API_BASE_URL
              value: "http://litellm.ai-platform.svc.cluster.local:4000/v1"
            - name: OPENAI_API_KEY
              valueFrom:
                secretKeyRef:
                  name: litellm-secrets
                  key: master-key
                  optional: true
            - name: WEBUI_AUTH
              value: "true"
          volumeMounts:
            - name: data
              mountPath: /app/backend/data
          readinessProbe:
            httpGet:
              path: /health
              port: 8080
            initialDelaySeconds: 15
          resources:
            requests:
              cpu: 250m
              memory: 512Mi
            limits:
              cpu: "1"
              memory: 2Gi
      volumes:
        - name: data
          persistentVolumeClaim:
            claimName: open-webui-data
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: open-webui-data
  namespace: ai-platform
spec:
  accessModes: ["ReadWriteOnce"]
  resources:
    requests:
      storage: 10Gi
---
apiVersion: v1
kind: Service
metadata:
  name: open-webui
  namespace: ai-platform
spec:
  type: ClusterIP
  selector:
    app: open-webui
  ports:
    - port: 8080
      targetPort: 8080
      name: http
---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: open-webui
  namespace: ai-platform
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app: open-webui
